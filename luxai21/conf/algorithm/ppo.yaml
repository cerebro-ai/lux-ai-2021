name: PPO

config:
  num_workers: 8
  num_envs_per_worker: 1


  rollout_fragment_length: 360
  train_batch_size: 2880
  num_sgd_iter: 2
  lr: 2e-4
  sgd_minibatch_size: 240
  batch_mode: "truncate_episodes"

  entropy_coeff: 1e-5