name: PPO

config:
  num_workers: 4
  num_envs_per_worker: 1

  gamma: 0.997

  rollout_fragment_length: 256
  train_batch_size: 1024
  num_sgd_iter: 10
  lr: 2e-4
  sgd_minibatch_size: 256
  batch_mode: "complete_episodes"

  entropy_coeff: 3e-5