---
wandb:
  entity: cerebro-ai
  project: luxai21
  notes: test notes

training:
  learning_rate: 0.001
  gamma: 0.995
  gae_lambda: 0.95
  batch_size: 128 # testing gradients
  step_count: 8388608
  n_steps: 8192
  n_envs: 1  # Number of parallel environments to use in training

model:
  map_emb_dim: 128
  # TODO insert feature_extractor parameters
  net_arch_shared_layers: [128]
  net_arch_pi: [64, 32] # policy-function
  net_arch_vf: [128, 64, 32] # value-function
  lstm_config:
    # supports all attributes of pytorch LSTM: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html
    # input_size is implicitly given through the map_emb_dim
    # batch_first is also always true
    hidden_size: 128
    num_layers: 4
    # dropout: 0.2

reward:
  units_factor: 0.05
  citytile_factor: 0.1
  citytile_end_factor: 2